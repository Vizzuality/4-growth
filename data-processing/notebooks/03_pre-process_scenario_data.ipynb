{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebf0c38d",
   "metadata": {},
   "source": [
    "# Pre-processing MMFT data for the 4-Growth Platform\n",
    "\n",
    "## Setup and Imports \n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3301f69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17b835b",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b66cacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local directory for raw data files (Excel sheets)\n",
    "INPUT_DATA_DIR = Path(\"../data/raw/D3.3/\")\n",
    "OUTPUT_DATA_DIR = Path(\"../data/processed/D3.3/\")\n",
    "\n",
    "# Forestry MMFT sheet names\n",
    "FORESTRY_MMFT_SHEET_NAMES = {\n",
    "    \"baseline\": \"Model - Baseline (VZZ)\",\n",
    "    \"reimagining_progress\": \"Scenario - Reimagining Progress\",\n",
    "    \"fractured_continent\": \"Scenario - Fractured Continent\",\n",
    "    \"corporate_epoch\": \"Scenario - Corporate Epoch\",\n",
    "}\n",
    "\n",
    "# Agriculture MMFT sheet names\n",
    "AGRICULTURE_MMFT_SHEET_NAMES = {\n",
    "    \"baseline\": \"Model - Baseline\",\n",
    "    \"reimagining_progress\": \"Scenario - Reimagining Progress\",\n",
    "    \"fractured_continent\": \"Scenario - Fractured Continent\",\n",
    "    \"corporate_epoch\": \"Scenario - Corporate Epoch\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196e9159",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b2a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split dataframe by sections (A-G markers in column 1)\n",
    "def split_by_sections(df_raw: pd.DataFrame) -> dict[str, pd.DataFrame]:  # noqa: PLR0912\n",
    "    \"\"\"\n",
    "    Split raw dataframe into separate dataframes for each section (A-G).\n",
    "\n",
    "    Data has sections stacked vertically with markers in column 1:\n",
    "    - A. Market potential\n",
    "    - B. Addressable market\n",
    "    - C. Penetration\n",
    "    - D. Shipments\n",
    "    - E. Installed base\n",
    "    - F. Prices\n",
    "    - G. Revenues\n",
    "\n",
    "    Returns:\n",
    "        dict mapping section names to their respective DataFrames\n",
    "    \"\"\"\n",
    "    # Define section patterns and their names\n",
    "    section_markers = {\n",
    "        \"A. Market\": \"market_potential\",\n",
    "        \"B. Addressable\": \"addressable_market\",\n",
    "        \"C. Penetration\": \"penetration\",\n",
    "        \"D. Shipments\": \"shipments\",\n",
    "        \"E. Installed\": \"installed_base\",\n",
    "        \"F. Prices\": \"prices\",\n",
    "        \"G. Revenues\": \"revenues\",\n",
    "    }\n",
    "\n",
    "    # Find row indices where each section starts - check multiple columns\n",
    "    section_starts = []\n",
    "    for row_idx in range(len(df_raw)):\n",
    "        # Check columns 0, 1, and 2 for section markers\n",
    "        for col_idx in range(min(3, len(df_raw.columns))):\n",
    "            val = df_raw.iloc[row_idx, col_idx]\n",
    "            if isinstance(val, str):\n",
    "                for marker, section_name in section_markers.items():\n",
    "                    if marker in val:\n",
    "                        section_starts.append((row_idx, section_name))\n",
    "                        break\n",
    "                else:\n",
    "                    continue\n",
    "                break\n",
    "\n",
    "    # Sort by row index\n",
    "    section_starts.sort(key=lambda x: x[0])\n",
    "\n",
    "    print(f\"  Found {len(section_starts)} section(s): {[s[1] for s in section_starts]}\")\n",
    "\n",
    "    # Split dataframe into sections\n",
    "    sections = {}\n",
    "    for i, (start_row, section_name) in enumerate(section_starts):\n",
    "        # End row is the start of next section, \"END\" marker, or end of dataframe\n",
    "        if i + 1 < len(section_starts):\n",
    "            end_row = section_starts[i + 1][0]\n",
    "        else:\n",
    "            # Look for END marker\n",
    "            end_row = len(df_raw)\n",
    "            for row_idx in range(start_row, len(df_raw)):\n",
    "                for col_idx in range(min(3, len(df_raw.columns))):\n",
    "                    val = df_raw.iloc[row_idx, col_idx]\n",
    "                    if isinstance(val, str) and val.strip() == \"END\":\n",
    "                        end_row = row_idx\n",
    "                        break\n",
    "                else:\n",
    "                    continue\n",
    "                break\n",
    "\n",
    "        # Find the header row (skip section marker row and any empty rows)\n",
    "        # The header row contains column names like \"Tech #\", \"Technology\", etc.\n",
    "        header_row = start_row + 1\n",
    "        for row_idx in range(start_row + 1, min(start_row + 5, end_row)):\n",
    "            # Check if this row has meaningful content (header row)\n",
    "            row_vals = df_raw.iloc[row_idx].dropna()\n",
    "            if len(row_vals) > 3:  # noqa: PLR2004\n",
    "                header_row = row_idx\n",
    "                break\n",
    "\n",
    "        # Extract section data starting from header row\n",
    "        section_df = df_raw.iloc[header_row:end_row].copy()\n",
    "\n",
    "        # Set column names from the first row of the section (header row)\n",
    "        section_df.columns = section_df.iloc[0]\n",
    "        section_df = section_df.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "        # Drop columns with NaN names and columns that are all NaN\n",
    "        section_df = section_df.loc[:, section_df.columns.notna()]\n",
    "        section_df = section_df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "        # Drop rows that are completely empty (all NaN)\n",
    "        section_df = section_df.dropna(how=\"all\")\n",
    "\n",
    "        # Convert year columns from float to int (e.g., 2020.0 -> 2020)\n",
    "        new_columns = []\n",
    "        for col in section_df.columns:\n",
    "            if isinstance(col, float) and col > 1900 and col < 2100:  # noqa: PLR2004\n",
    "                new_columns.append(int(col))\n",
    "            else:\n",
    "                new_columns.append(col)\n",
    "        section_df.columns = new_columns\n",
    "\n",
    "        sections[section_name] = section_df\n",
    "        print(f\"  {section_name}: {len(section_df)} rows, {len(section_df.columns)} columns\")\n",
    "\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2452243",
   "metadata": {},
   "source": [
    "## Data Loading and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a33be4",
   "metadata": {},
   "source": [
    "### Load Data from Google Sheets\n",
    "**Forestry MMFT Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2983219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model - Baseline (VZZ): 1627 rows\n",
      "Loaded Scenario - Reimagining Progress: 1627 rows\n",
      "Loaded Scenario - Fractured Continent: 1627 rows\n",
      "Loaded Scenario - Corporate Epoch: 1627 rows\n"
     ]
    }
   ],
   "source": [
    "forest_data: dict[str, pd.DataFrame] = {}\n",
    "\n",
    "for table_name, sheet_name in FORESTRY_MMFT_SHEET_NAMES.items():\n",
    "    forest_data[table_name] = pd.read_excel(\n",
    "        INPUT_DATA_DIR / \"D3.3-Forestry_MMFT_VZZ.xlsx\", sheet_name=sheet_name, header=2\n",
    "    )\n",
    "    print(f\"Loaded {sheet_name}: {len(forest_data[table_name])} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c82ec1d",
   "metadata": {},
   "source": [
    "**Agriculture MMFT Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe21201e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model - Baseline: 4781 rows\n",
      "Loaded Scenario - Reimagining Progress: 4779 rows\n",
      "Loaded Scenario - Fractured Continent: 4779 rows\n",
      "Loaded Scenario - Corporate Epoch: 4779 rows\n"
     ]
    }
   ],
   "source": [
    "agriculture_data: dict[str, pd.DataFrame] = {}\n",
    "\n",
    "for table_name, sheet_name in AGRICULTURE_MMFT_SHEET_NAMES.items():\n",
    "    agriculture_data[table_name] = pd.read_excel(\n",
    "        INPUT_DATA_DIR / \"D3.3-Agriculture_MMFT_VZZ.xlsx\", sheet_name=sheet_name, header=3\n",
    "    )\n",
    "    print(f\"Loaded {sheet_name}: {len(agriculture_data[table_name])} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99799dbf",
   "metadata": {},
   "source": [
    "### Clean and Transform Data\n",
    "**Forestry MMFT Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2987cfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting forestry baseline data by sections:\n",
      "  Found 7 section(s): ['market_potential', 'addressable_market', 'penetration', 'shipments', 'installed_base', 'prices', 'revenues']\n",
      "  market_potential: 238 rows, 29 columns\n",
      "  addressable_market: 238 rows, 29 columns\n",
      "  penetration: 204 rows, 29 columns\n",
      "  shipments: 238 rows, 29 columns\n",
      "  installed_base: 204 rows, 29 columns\n",
      "  prices: 238 rows, 29 columns\n",
      "  revenues: 238 rows, 29 columns\n",
      "Splitting forestry reimagining_progress data by sections:\n",
      "  Found 7 section(s): ['market_potential', 'addressable_market', 'penetration', 'shipments', 'installed_base', 'prices', 'revenues']\n",
      "  market_potential: 238 rows, 29 columns\n",
      "  addressable_market: 238 rows, 29 columns\n",
      "  penetration: 204 rows, 29 columns\n",
      "  shipments: 238 rows, 29 columns\n",
      "  installed_base: 204 rows, 29 columns\n",
      "  prices: 238 rows, 29 columns\n",
      "  revenues: 238 rows, 29 columns\n",
      "Splitting forestry fractured_continent data by sections:\n",
      "  Found 7 section(s): ['market_potential', 'addressable_market', 'penetration', 'shipments', 'installed_base', 'prices', 'revenues']\n",
      "  market_potential: 238 rows, 29 columns\n",
      "  addressable_market: 238 rows, 29 columns\n",
      "  penetration: 204 rows, 29 columns\n",
      "  shipments: 238 rows, 29 columns\n",
      "  installed_base: 204 rows, 29 columns\n",
      "  prices: 238 rows, 29 columns\n",
      "  revenues: 238 rows, 29 columns\n",
      "Splitting forestry corporate_epoch data by sections:\n",
      "  Found 7 section(s): ['market_potential', 'addressable_market', 'penetration', 'shipments', 'installed_base', 'prices', 'revenues']\n",
      "  market_potential: 238 rows, 29 columns\n",
      "  addressable_market: 238 rows, 29 columns\n",
      "  penetration: 204 rows, 29 columns\n",
      "  shipments: 238 rows, 29 columns\n",
      "  installed_base: 204 rows, 29 columns\n",
      "  prices: 238 rows, 29 columns\n",
      "  revenues: 238 rows, 29 columns\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "for scenario, df in forest_data.items():\n",
    "    print(f\"Splitting forestry {scenario} data by sections:\")\n",
    "    forest_sections = split_by_sections(df)\n",
    "\n",
    "    for n, (section_name, section_df) in enumerate(forest_sections.items()):\n",
    "        section_df[\"Indicator\"] = section_name\n",
    "        if n == 0:\n",
    "            forest_combined = section_df\n",
    "        else:\n",
    "            forest_combined = pd.concat([forest_combined, section_df], ignore_index=True)\n",
    "\n",
    "    forest_combined.to_csv(OUTPUT_DATA_DIR / f\"forestry_{scenario}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b70deea",
   "metadata": {},
   "source": [
    "**Agriculture MMFT Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31601b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting agriculture baseline data by sections:\n",
      "  Found 7 section(s): ['market_potential', 'addressable_market', 'penetration', 'shipments', 'installed_base', 'prices', 'revenues']\n",
      "  market_potential: 646 rows, 28 columns\n",
      "  addressable_market: 646 rows, 27 columns\n",
      "  penetration: 646 rows, 27 columns\n",
      "  shipments: 714 rows, 27 columns\n",
      "  installed_base: 714 rows, 27 columns\n",
      "  prices: 646 rows, 26 columns\n",
      "  revenues: 714 rows, 27 columns\n",
      "Splitting agriculture reimagining_progress data by sections:\n",
      "  Found 6 section(s): ['addressable_market', 'penetration', 'shipments', 'installed_base', 'prices', 'revenues']\n",
      "  addressable_market: 646 rows, 27 columns\n",
      "  penetration: 646 rows, 27 columns\n",
      "  shipments: 714 rows, 27 columns\n",
      "  installed_base: 714 rows, 27 columns\n",
      "  prices: 646 rows, 26 columns\n",
      "  revenues: 714 rows, 27 columns\n",
      "Splitting agriculture fractured_continent data by sections:\n",
      "  Found 6 section(s): ['addressable_market', 'penetration', 'shipments', 'installed_base', 'prices', 'revenues']\n",
      "  addressable_market: 646 rows, 27 columns\n",
      "  penetration: 646 rows, 27 columns\n",
      "  shipments: 714 rows, 27 columns\n",
      "  installed_base: 714 rows, 27 columns\n",
      "  prices: 646 rows, 26 columns\n",
      "  revenues: 714 rows, 27 columns\n",
      "Splitting agriculture corporate_epoch data by sections:\n",
      "  Found 6 section(s): ['addressable_market', 'penetration', 'shipments', 'installed_base', 'prices', 'revenues']\n",
      "  addressable_market: 646 rows, 27 columns\n",
      "  penetration: 646 rows, 27 columns\n",
      "  shipments: 714 rows, 27 columns\n",
      "  installed_base: 714 rows, 27 columns\n",
      "  prices: 646 rows, 26 columns\n",
      "  revenues: 714 rows, 27 columns\n"
     ]
    }
   ],
   "source": [
    "for scenario, df in agriculture_data.items():\n",
    "    print(f\"Splitting agriculture {scenario} data by sections:\")\n",
    "    agriculture_sections = split_by_sections(df)\n",
    "\n",
    "    for n, (section_name, section_df) in enumerate(agriculture_sections.items()):\n",
    "        section_df[\"Indicator\"] = section_name\n",
    "        if n == 0:\n",
    "            agriculture_combined = section_df\n",
    "        else:\n",
    "            agriculture_combined = pd.concat([agriculture_combined, section_df], ignore_index=True)\n",
    "\n",
    "    agriculture_combined.to_csv(OUTPUT_DATA_DIR / f\"agriculture_{scenario}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
